{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "739ed711",
   "metadata": {},
   "source": [
    "# Chapter 13 - Loading and Preprocessing Data With TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5210ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb4b00",
   "metadata": {},
   "source": [
    "## The Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a48b5c",
   "metadata": {},
   "source": [
    "The data API makes it possible for reading data with tensorflow and preprocess it. you just create a dataset object, and tell it where to get the data and how to transform it. TensorFlow takes care of all the implementation details, such as multithreading, queuing, batching, and prefetching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337e5bb",
   "metadata": {},
   "source": [
    "The whole Data API revolves around the concept of a dataset: as you might suspect, this represents a sequence of data items. Usually you will use datasets that gradually read data from disk, but for simplicity let’s create a dataset entirely in RAM using `tf.data.Dataset.from_tensor_slices()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6329dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3753a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875212ff",
   "metadata": {},
   "source": [
    "### Chaining Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e4102",
   "metadata": {},
   "source": [
    "Once you have a dataset, you can apply all sorts of transformations to it by calling its transformation methods. Each method returns a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd7c34c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7)\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61db314",
   "metadata": {},
   "source": [
    "Keep in mind that the dataset methods do not modify the dataset, they create new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4e0816d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  4  9 16 25 36], shape=(7,), dtype=int32)\n",
      "tf.Tensor([49 64 81  0  1  4  9], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 25 36 49 64 81  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 1  4  9 16 25 36 49], shape=(7,), dtype=int32)\n",
      "tf.Tensor([64 81], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# the map method transform item/batch by item/batch\n",
    "dataset = dataset.map(lambda x: x ** 2)\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e28b810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the apply method transforms the whole dataset\n",
    "dataset = dataset.apply(tf.data.experimental.unbatch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d396702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataset instances\n",
    "dataset = dataset.filter(lambda x: x < 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0503552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# the take method let us look at a portion of the dataset\n",
    "for item in dataset.take(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d1e2c",
   "metadata": {},
   "source": [
    "### Shuffling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed6d2ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 6], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(3) # 0 to 9, three times\n",
    "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d78bb",
   "metadata": {},
   "source": [
    "Considerations about this method of shuffling must be raised. One might set a batch size to a low value such that everytime a batch is sampled, the dataset may not appear to be sampled iid. One approach is to split the dataset into multiple files and read them simultaneously in **interleaved order**. To know more about this approach, go to the notebook in the book's repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc010cac",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b363fdce",
   "metadata": {},
   "source": [
    "Preprocessing the data go as usual, but in the context of tensorflow, we must consider the rules to make TF functions, discussed in the last chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee228589",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## The TFRecord Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4deaa0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The TFRecord format is TensorFlow’s preferred format for storing large amounts of data and reading it efficiently. You can easily create a TFRecord file using the `tf.io.TFRecordWriter` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ede46e15",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"./datasets/tfrecord_format_sample/my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bec44884",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "filepaths = [\"./datasets/tfrecord_format_sample/my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd786156",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By default, a `TFRecordDataset` will read files one by one, but you can make it read multiple files in parallel and interleave their records by setting `num_parallel_reads`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591826e2",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Compressed TFRecord Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a9adb6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It can sometimes be useful to compress your TFRecord files, especially if they need to be loaded via a network connection. You can create a compressed TFRecord file by setting the `options` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4cf171c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "# with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "#     [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54050d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When reading a compressed TFRecord file, you need to specify the compression type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8171f934",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"], compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cde35b",
   "metadata": {},
   "source": [
    "## Preprocessing the Input Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e1135",
   "metadata": {},
   "source": [
    "There are several alternative ways to preprocess the data for a neural network. In this chapter, we are going to use the approach of using a preprocessing layer directly in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d783c",
   "metadata": {},
   "source": [
    "For example, here is how you can implement a standardization layer using a `Lambda` layer. For each feature, it subtracts the mean and divides by its standard deviation (plus a tiny smoothing term to avoid division by zero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc5fd5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = np.mean(X_train, axis=0, keepdims=True)\n",
    "# stds = np.std(X_train, axis=0, keepdims=True)\n",
    "# eps = keras.backend.epsilon()\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "# keras.layers.Lambda(lambda inputs: (inputs - means) / (stds + eps)),\n",
    "#     [...] # other layers\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd20fc",
   "metadata": {},
   "source": [
    "And instead of having to declare global variables, we can declare a Standardization class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a810814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d6df3",
   "metadata": {},
   "source": [
    "Before you can use this standardization layer, you will need to adapt it to your dataset by calling the `adapt()` method and passing it a data sample. This will allow it to use the appropriate mean and standard deviation for each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0507b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_layer = Standardization()\n",
    "# std_layer.adapt(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b492b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(std_layer)\n",
    "# [...] # create the rest of the model\n",
    "# model.compile([...])\n",
    "# model.fit([...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce01098",
   "metadata": {},
   "source": [
    "### Encoding Categorial Features Using One-Hot Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f3b3c2",
   "metadata": {},
   "source": [
    "Consider the `ocean_proximity` feature in the California housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5ad447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "num_oov_buckets = 2\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee435cd",
   "metadata": {},
   "source": [
    "- We first define the vocabulary: this is the list of all possible categories.\n",
    "- Then we create a tensor with the corresponding indices (0 to 4).\n",
    "- Next, we create an initializer for the lookup table, passing it the list of categories and their corresponding indices.\n",
    "- In the last two lines we create the lookup table, giving it the initializer and specifying the number of out-of-vocabulary (oov) buckets. If we look up a category that does not exist in the vocabulary, the lookup table will compute a hash of this category and use it to assign the unknown category to one of the oov buckets. Their indices start after the known categories, so in this example the indices of the two oov buckets are 5 and 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8697d3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f7ade7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)\n",
    "cat_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e219b7",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features Using Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1952b55",
   "metadata": {},
   "source": [
    "**An embedding is a trainable dense vector that represents a category**. By default, embeddings are initialized randomly, so for example the \"NEAR BAY\" category could be represented initially by a random vector such as [0.131, 0.890], while the \"NEAR OCEAN\" category might be represented by another random vector such as [0.631, 0.791]. In this example, we use 2D embeddings, but the number of dimensions is a hyperparameter you can tweak. Since these embeddings are trainable, they will gradually improve during training; and as they represent fairly similar categories, Gradient Descent will certainly end up pushing them closer together, while it will tend to move them away from the \"INLAND\" category’s embedding (see Figure 13-4). Indeed, the better the representation, the easier it will be for the neural network to make accurate predictions, so training tends to make embeddings useful representations of the categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf7f8e",
   "metadata": {},
   "source": [
    "Let’s look at how we could implement embeddings manually, to understand how they work (then we will use a simple Keras layer instead). First, we need to create an embedding matrix containing each category’s embedding, initialized randomly; it will have one row per category and per oov bucket, and one column per embedding dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e83724f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 2\n",
    "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
    "embedding_matrix = tf.Variable(embed_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7da4533c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
       "array([[0.13770425, 0.61187863],\n",
       "       [0.99558365, 0.87079966],\n",
       "       [0.39352548, 0.27532458],\n",
       "       [0.59721243, 0.78619385],\n",
       "       [0.05042589, 0.20825803],\n",
       "       [0.34178567, 0.19068134],\n",
       "       [0.46905756, 0.38303804]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57fce8",
   "metadata": {},
   "source": [
    "We are using embeddings of 2 dimensions, but as a rule of thumb, use between 10 and 300 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d668717c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d3434bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.59721243, 0.78619385],\n",
       "       [0.34178567, 0.19068134],\n",
       "       [0.99558365, 0.87079966],\n",
       "       [0.99558365, 0.87079966]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311f817",
   "metadata": {},
   "source": [
    "The `tf.nn.embedding_lookup()` function looks up the rows in the embedding matrix, at the given indices—that’s all it does. Keras provides a `keras.layers.Embedding` layer that handles the embedding matrix (trainable, by default); when the layer is created it initializes the embedding matrix randomly, and then when it is called with some category indices it returns the rows at those indices in the embedding matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6970df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = keras.layers.Embedding(input_dim=len(vocab) + num_oov_buckets, \n",
    "                                   output_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ae0a392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[-0.00029554, -0.03557222],\n",
       "       [-0.03858506,  0.01033878],\n",
       "       [-0.01497278,  0.00052623],\n",
       "       [-0.01497278,  0.00052623]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(cat_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011c34e",
   "metadata": {},
   "source": [
    "Putting everything together, we can now have a model that handles numerical and categorical features, as well as oov buckets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e66cf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_inputs = keras.layers.Input(shape=[8])\n",
    "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories],\n",
    "                           outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73bd286",
   "metadata": {},
   "source": [
    "This model takes two inputs: a regular input containing eight numerical features per instance, plus a categorical input (containing one categorical feature per instance). It uses a Lambda layer to look up each category’s index, then it looks up the embeddings for these indices. Next, it concatenates the embeddings and the regular inputs in order to give the encoded inputs, which are ready to be fed to a neural network.\n",
    "\n",
    "When the `keras.layers.TextVectorization` layer is available, you can call its `adapt()` method to make it extract the vocabulary from a data sample (it will take care of creating the lookup table for you). Then you can add it to your model, and it will perform the index lookup (replacing the Lambda layer in the previous code example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e5bc97",
   "metadata": {},
   "source": [
    "### Keras Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb198f5",
   "metadata": {},
   "source": [
    "We can define a preprocessing layers much like a pipeline that behaves as a layers applying preprocessing step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4bb95124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization = keras.layers.Normalization()\n",
    "# discretization = keras.layers.Discretization([...])\n",
    "# pipeline = keras.layers.PreprocessingStage([normalization, discretization])\n",
    "# pipeline.adapt(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081aefa",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f63a4b",
   "metadata": {},
   "source": [
    "**1. Why would you want to use the Data API?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebb06d",
   "metadata": {},
   "source": [
    "The Data API is integrated with some TensorFlow features in such a way that, if used together, advanced operations such as multithreading, queueing, batching, and prefetching are handle automatically. Moreover, the Data API works seamlessly with `tf.keras`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a7234",
   "metadata": {},
   "source": [
    "**2. What are the benefits of splitting a large dataset into multiple files?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c035781",
   "metadata": {},
   "source": [
    "First, we must consider what is recommended to do regarding shuffling data from small datasets. Once we have a dataset, we must shuffle it to feed it to the SGD optimization algoritm. Therefore, we effectively created a new dataset with shuffled data. Then, we create a buffer fill it up a buffer with the instances of the dataset and whenever the model asks for an instance, it will be retrieved from the buffer until the buffer is emptied and the whole process starts again until the whole dataset has been seen by the model. \n",
    "\n",
    "It is in our hands to choose the buffer size, and we must do so such that the buffer size is not too small, or else, shuffling will not be very effective. Considering this, arises a problem with large datasets.\n",
    "\n",
    "Large datasets don't fit in memory and apart from that, if the dataset is too large, the buffer size will be fatally small compared to the dataset size, which destroys the effects of shuffling. The alternative we have is to shuffle the data source itself. To do that, we shuffle the data and split is in several files with reasonable sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02ad5c",
   "metadata": {},
   "source": [
    "**3. During training, how can you tell that your input pipeline is the bottleneck? What can you do to fix it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86085027",
   "metadata": {},
   "source": [
    "You can use TensorBoard to visualize profiling data: if the GPU is not fully utilized then your input pipeline is likely to be the bottleneck. You can fix it by making sure it reads and preprocesses the data in multiple threads in parallel, and ensuring it prefetches a few batches. If this is insufficient to get your GPU to 100% usage during training, make sure your preprocessing code is optimized. You can also try saving the dataset into multiple TFRecord files, and if necessary perform some of the preprocessing ahead of time so that it does not need to be done on the fly during training (TF Transform can help with this). If necessary, use a machine with more CPU and RAM, and ensure that the GPU bandwidth is large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9122655",
   "metadata": {},
   "source": [
    "**4. Can you save any binary data to a TFRecord file, or only serialized\n",
    "protocol buffers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1876f23",
   "metadata": {},
   "source": [
    "TFRecord files can store arbitrary binary records but usually it is used to store file in serialized protocol buffers (protobufs) format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3be4ca",
   "metadata": {},
   "source": [
    "**5. Why would you go through the hassle of converting all your data to the Example protobuf format? Why not use your own protobuf definition?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d3685",
   "metadata": {},
   "source": [
    "Creating our own protobuf definition may be simpler. To transmit it through a network, we would need to serialize (`SerializeToString()`) and parse (`ParseFromString()`) the data. These operations are not TensorFlow operations, so they cannot be included in a TensorFlow Function. Nevertheless, TensorFlow does include special protobuf definitions for whith it provides parsing operations, one of them is the `Example` protobuf.\n",
    "\n",
    "However, if it does not cover your use case, you can define your own protocol buffer, compile it using protoc (setting the --descriptor_set_out and --include_imports arguments to export the protobuf descriptor), and use the tf.io.decode_proto() function to parse the serialized protobufs (see the “Custom protobuf” section of the notebook for an example). It’s more complicated, and it requires deploying the descriptor along with the model, but it can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe1bf0",
   "metadata": {},
   "source": [
    "**6. When using TFRecords, when would you want to activate compression? Why not do it systematically?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefcc58e",
   "metadata": {},
   "source": [
    "Compression is only recommended when the files are in another machine and they must be downloaded for training in another machine. By applying compression to this situation, the download will run much faster because the dataset will have a smaller file size. On the other hand, if the dataset is in the same machine that will consume it, there is no need for compression because we would just waste resources having to decompress the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4f4e8",
   "metadata": {},
   "source": [
    "**7. Data can be preprocessed directly when writing the data files, or within the tf.data pipeline, or in preprocessing layers within your model, or using TF Transform. Can you list a few pros and cons of each option?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb5e33",
   "metadata": {},
   "source": [
    "If you preprocess the data when creating the data files, the\n",
    "training script will run faster, since it will not have to perform\n",
    "preprocessing on the fly. In some cases, the preprocessed data\n",
    "will also be much smaller than the original data, so you can\n",
    "save some space and speed up downloads. It may also be\n",
    "helpful to materialize the preprocessed data, for example to\n",
    "inspect it or archive it. However, this approach has a few cons.\n",
    "First, it’s not easy to experiment with various preprocessing\n",
    "logics if you need to generate a preprocessed dataset for each\n",
    "variant. Second, if you want to perform data augmentation, you\n",
    "have to materialize many variants of your dataset, which will\n",
    "use a large amount of disk space and take a lot of time to\n",
    "generate. Lastly, the trained model will expect preprocessed\n",
    "data, so you will have to add preprocessing code in your\n",
    "application before it calls the model.\n",
    "\n",
    "If the data is preprocessed with the tf.data pipeline, it’s much\n",
    "easier to tweak the preprocessing logic and apply data\n",
    "augmentation. Also, tf.data makes it easy to build highly\n",
    "efficient preprocessing pipelines (e.g., with multithreading and\n",
    "prefetching). However, preprocessing the data this way will\n",
    "slow down training. Moreover, each training instance will be\n",
    "preprocessed once per epoch rather than just once if the data\n",
    "was preprocessed when creating the data files. Lastly, the\n",
    "trained model will still expect preprocessed data.\n",
    "\n",
    "If you add preprocessing layers to your model, you will only\n",
    "have to write the preprocessing code once for both training and\n",
    "inference. If your model needs to be deployed to many\n",
    "different platforms, you will not need to write the\n",
    "preprocessing code multiple times. Plus, you will not run the\n",
    "risk of using the wrong preprocessing logic for your model,\n",
    "since it will be part of the model. On the downside,\n",
    "preprocessing the data will slow down training, and each\n",
    "training instance will be preprocessed once per epoch.\n",
    "Moreover, by default the preprocessing operations will run on\n",
    "the GPU for the current batch (you will not benefit from\n",
    "parallel preprocessing on the CPU, and prefetching).\n",
    "Fortunately, the upcoming Keras preprocessing layers should\n",
    "be able to lift the preprocessing operations from the\n",
    "preprocessing layers and run them as part of the tf.data\n",
    "pipeline, so you will benefit from multithreaded execution on\n",
    "the CPU and prefetching.\n",
    "\n",
    "Lastly, using TF Transform for preprocessing gives you many\n",
    "of the benefits from the previous options: the preprocessed data\n",
    "is materialized, each instance is preprocessed just once\n",
    "(speeding up training), and preprocessing layers get generated\n",
    "automatically so you only need to write the preprocessing code\n",
    "once. The main drawback is the fact that you need to learn how\n",
    "to use this tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143bf20",
   "metadata": {},
   "source": [
    "**8. Name a few common techniques you can use to encode categorical features. What about text?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dde007",
   "metadata": {},
   "source": [
    "Ordinal encoding, one-hot encodding. TF-IDF, bag of words, word embeddings (for text)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7712606d",
   "metadata": {},
   "source": [
    "**9. Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized Example protobuf with two features: the serialized image (use `tf.io.serialize_tensor()` to serialize each image), and the label. Then use `tf.data` to create an efficient dataset for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the\n",
    "input pipeline as efficient as possible, using TensorBoard to visualize profiling data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9137726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BytesList = tf.train.BytesList\n",
    "FloatList = tf.train.FloatList\n",
    "Int64List = tf.train.Int64List\n",
    "Feature = tf.train.Feature\n",
    "Features = tf.train.Features\n",
    "Example = tf.train.Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40dbb10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the fashion mnist dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "548ebb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training/validation sets\n",
    "X_val, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_val, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e143d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the training set\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdd84195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4b9c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert images and labels into Examples\n",
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    \n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label]))\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68ef890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, label in valid_set.take(1):\n",
    "#     print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56530baa",
   "metadata": {},
   "source": [
    "The following function saves a given dataset to a set of TFRecord files. **The examples are written to the files in a round-robin fashion**. To do this, we enumerate all the examples using the `dataset.enumerate()` method, and we compute `index % n_shards` to decide which file to write to. We use the standard `contextlib.ExitStack` class to make sure that all writers are properly closed whether or not an I/O error occurs while writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8baee3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards)\n",
    "             for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                   for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9963debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset in tfrecords format\n",
    "train_filepaths = write_tfrecords(\"datasets/ch13_ex09/my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"datasets/ch13_ex09/my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"datasets/ch13_ex09/my_fashion_mnist.test\", test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1ef5ec",
   "metadata": {},
   "source": [
    "Using `tf.data` to create an efficient dataset for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40401422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f610a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                  n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                      num_parallel_reads=n_read_threads)\n",
    "    \n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    \n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7cc91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e88075e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e84d30",
   "metadata": {},
   "source": [
    "Adding a standardization preprocessing layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc3cd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
    "    \n",
    "    \n",
    "standardization = Standardization(input_shape=[28, 28])\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                               axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b15ff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 231.8194 - accuracy: 0.8407 - val_loss: 1731.3500 - val_accuracy: 0.8702\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 513.7507 - accuracy: 0.8788 - val_loss: 987.4476 - val_accuracy: 0.8812\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 412.7268 - accuracy: 0.8910 - val_loss: 53.1468 - val_accuracy: 0.8824\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 232.7943 - accuracy: 0.8990 - val_loss: 117.3360 - val_accuracy: 0.8778\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 137.5280 - accuracy: 0.9082 - val_loss: 64.0788 - val_accuracy: 0.8832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f114ec89820>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d6437",
   "metadata": {},
   "source": [
    "**10. In this exercise you will download a dataset, split it, create a `tf.data.Dataset` to load it and preprocess it efficiently, then build and train a binary classification model containing an Embedding layer:**\n",
    "\n",
    "**a. Download the Large Movie Review Dataset, which contains 50,000 movies reviews from the Internet Movie Database. The data is organized in two directories, train and test, each containing a pos subdirectory with 12,500 positive reviews and a neg subdirectory with 12,500 negative reviews. Each review is stored in a separate text file. There are other files and folders (including preprocessed bag-of-words), but we will ignore them in this exercise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29d0c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 15:59:46.741648: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-16 15:59:46.741672: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "path = Path(\"./datasets/aclImdb_v1/aclImdb\")\n",
    "\n",
    "def review_paths(dirpath):\n",
    "    return [str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_valid_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_valid_neg = review_paths(path / \"test\" / \"neg\")\n",
    "\n",
    "len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34355b3d",
   "metadata": {},
   "source": [
    "**b. Split the test set into a validation set (15,000) and a test set (10,000).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d603d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(test_valid_pos)\n",
    "\n",
    "test_pos = test_valid_pos[:5000]\n",
    "test_neg = test_valid_neg[:5000]\n",
    "valid_pos = test_valid_pos[5000:]\n",
    "valid_neg = test_valid_neg[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7229034b",
   "metadata": {},
   "source": [
    "**c. Use tf.data to create an efficient dataset for each set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c00013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath) as review_file:\n",
    "                reviews.append(review_file.read())\n",
    "            labels.append(label)\n",
    "    return tf.data.Dataset.from_tensor_slices((tf.constant(reviews), tf.constant(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef3084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 15:59:49.259289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-16 15:59:49.259314: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-16 15:59:49.259329: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (BRSPOBITANL1634): /proc/driver/nvidia/version does not exist\n",
      "2022-02-16 15:59:49.259576: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set = imdb_dataset(train_pos, train_neg).shuffle(25000).batch(batch_size).prefetch(1)\n",
    "valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)\n",
    "test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "05c0fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X, y in imdb_dataset(train_pos, train_neg).take(3):\n",
    "#     print(X)\n",
    "#     print(y)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d026f1",
   "metadata": {},
   "source": [
    "**d. Create a binary classification model, using a `TextVectorization` layer to preprocess each review. If the\n",
    "`TextVectorization` layer is not yet available (or if you like a challenge), try to create your own custom preprocessing layer: you can use the functions in the `tf.strings` package, for example `lower()` to make everything lowercase, `regex_replace()` to replace punctuation with spaces, and `split()` to split words on spaces. You should use a lookup table to output word indices, which must be prepared in the `adapt()` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d742f2",
   "metadata": {},
   "source": [
    "Let's first write a function to preprocess the reviews, cropping them to 300 characters, converting them to lower case, then replacing `<br />` and all non-letter characters to spaces, splitting the reviews into words, and finally padding or cropping each review so it ends up with exactly `n_words` tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6caa965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=string, numpy=\n",
       "array([[b'it', b's', b'a', b'great', b'great', b'movie', b'i', b'loved',\n",
       "        b'it', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
       "       [b'it', b'was', b'terrible', b'run', b'away', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
       "        b'<pad>']], dtype=object)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(X_batch, n_words=50):\n",
    "    shape = tf.shape(X_batch) * tf.constant([1, 0]) + tf.constant([0, n_words])\n",
    "    Z = tf.strings.substr(X_batch, 0, 300)\n",
    "    Z = tf.strings.lower(Z)\n",
    "    Z = tf.strings.regex_replace(Z, b\"<br\\\\s*/?>\", b\" \")\n",
    "    Z = tf.strings.regex_replace(Z, b\"[^a-z]\", b\" \")\n",
    "    Z = tf.strings.split(Z)\n",
    "    return Z.to_tensor(shape=shape, default_value=b\"<pad>\")\n",
    "\n",
    "X_example = tf.constant([\"It's a great, great movie! I loved it.\", \"It was terrible, run away!!!\"])\n",
    "preprocess(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367cb43",
   "metadata": {},
   "source": [
    "Now let's write a second utility function that will take a data sample with the same format as the output of the `preprocess()` function, and will output the list of the top max_size most frequent words, ensuring that the padding token is first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3106a54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>',\n",
       " b'it',\n",
       " b'great',\n",
       " b's',\n",
       " b'a',\n",
       " b'movie',\n",
       " b'i',\n",
       " b'loved',\n",
       " b'was',\n",
       " b'terrible',\n",
       " b'run',\n",
       " b'away']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_vocabulary(data_sample, max_size=1000):\n",
    "    preprocessed_reviews = preprocess(data_sample).numpy()\n",
    "    counter = Counter()\n",
    "    for words in preprocessed_reviews:\n",
    "        for word in words:\n",
    "            if word != b\"<pad>\":\n",
    "                counter[word] += 1\n",
    "    return [b\"<pad>\"] + [word for word, count in counter.most_common(max_size)]\n",
    "\n",
    "get_vocabulary(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116e7c2",
   "metadata": {},
   "source": [
    "Now we are ready to create the `TextVectorization` layer. Its constructor just saves the hyperparameters (`max_vocabulary_size` and `n_oov_buckets`). The `adapt()` method computes the vocabulary using the `get_vocabulary()` function, then it builds a `StaticVocabularyTable` (see Chapter 16 for more details). The `call()` method preprocesses the reviews to get a padded list of words for each review, then it uses the `StaticVocabularyTable` to lookup the index of each word in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "22b58eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorization(keras.layers.Layer):\n",
    "    def __init__(self, max_vocabulary_size=1000, n_oov_buckets=100, dtype=tf.string, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.max_vocabulary_size = max_vocabulary_size\n",
    "        self.n_oov_buckets = n_oov_buckets\n",
    "\n",
    "    def adapt(self, data_sample):\n",
    "        self.vocab = get_vocabulary(data_sample, self.max_vocabulary_size)\n",
    "        words = tf.constant(self.vocab)\n",
    "        word_ids = tf.range(len(self.vocab), dtype=tf.int64)\n",
    "        vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "        self.table = tf.lookup.StaticVocabularyTable(vocab_init, self.n_oov_buckets)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        preprocessed_inputs = preprocess(inputs)\n",
    "        return self.table.lookup(preprocessed_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "da564ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[ 1,  3,  4,  2,  2,  5,  6,  7,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [ 1,  8,  9, 10, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0]])>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization = TextVectorization()\n",
    "\n",
    "text_vectorization.adapt(X_example)\n",
    "text_vectorization(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3506ecff",
   "metadata": {},
   "source": [
    "Looks good! As you can see, each review was cleaned up and tokenized, then each word was encoded as its index in the vocabulary (all the 0s correspond to the `<pad>` tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9444d",
   "metadata": {},
   "source": [
    "Now let's create another `TextVectorization` layer and let's adapt it to the full IMDB training set (if the training set did not fit in RAM, we could just use a smaller sample of the training set by calling `train_set.take(500)`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9dccd2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocabulary_size = 1000\n",
    "n_oov_buckets = 100\n",
    "\n",
    "sample_review_batches = train_set.map(lambda review, label: review)\n",
    "sample_reviews = np.concatenate(list(sample_review_batches.as_numpy_iterator()),\n",
    "                                axis=0)\n",
    "\n",
    "text_vectorization = TextVectorization(max_vocabulary_size, n_oov_buckets,\n",
    "                                       input_shape=[])\n",
    "\n",
    "text_vectorization.adapt(sample_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5e191b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=int64, numpy=\n",
       "array([[  9,  14,   2,  64,  64,  12,   5, 256,   9,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  9,  13, 269, 532, 335,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization(X_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f8891",
   "metadata": {},
   "source": [
    "Now to build our model we will need to encode all these word IDs somehow. One approach is to create bags of words: for each review, and for each word in the vocabulary, we count the number of occurences of that word in the review. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f5002f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[2., 2., 0., 1.],\n",
       "       [3., 0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_example = tf.constant([[1, 3, 1, 0, 0], [2, 2, 0, 0, 0]])\n",
    "tf.reduce_sum(tf.one_hot(simple_example, 4), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09e57b",
   "metadata": {},
   "source": [
    "The first review has 2 times the word 0, 2 times the word 1, 0 times the word 2, and 1 time the word 3, so its bag-of-words representation is [2, 2, 0, 1]. Similarly, the second review has 3 times the word 0, 0 times the word 1, and so on. Let's wrap this logic in a small custom layer, and let's test it. We'll drop the counts for the word 0, since this corresponds to the `<pad>` token, which we don't care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f73cf9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords(keras.layers.Layer):\n",
    "    def __init__(self, n_tokens, dtype=tf.int32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.n_tokens = n_tokens\n",
    "    def call(self, inputs):\n",
    "        one_hot = tf.one_hot(inputs, self.n_tokens)\n",
    "        return tf.reduce_sum(one_hot, axis=1)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "02056244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[2., 0., 1.],\n",
       "       [0., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = BagOfWords(n_tokens=4)\n",
    "bag_of_words(simple_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ac5b67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = max_vocabulary_size + n_oov_buckets + 1 # add 1 for <pad>\n",
    "bag_of_words = BagOfWords(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1434f82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5419 - accuracy: 0.7207 - val_loss: 0.5148 - val_accuracy: 0.7383\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4690 - accuracy: 0.7673 - val_loss: 0.5042 - val_accuracy: 0.7417\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.4180 - accuracy: 0.8070 - val_loss: 0.5068 - val_accuracy: 0.7443\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3470 - accuracy: 0.8534 - val_loss: 0.5407 - val_accuracy: 0.7363\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2634 - accuracy: 0.9031 - val_loss: 0.5719 - val_accuracy: 0.7322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1148407250>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    bag_of_words,\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02e7b3",
   "metadata": {},
   "source": [
    "We get about 73.5% accuracy on the validation set after just the first epoch, but after that the model makes no significant progress. We will do better in Chapter 16. For now the point is just to perform efficient preprocessing using `tf.data` and Keras preprocessing layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3eb44a",
   "metadata": {},
   "source": [
    "**e. Add an Embedding layer and compute the mean embedding for each review, multiplied by the square root of the number of words (see Chapter 16). This rescaled mean embedding can then be passed to the rest of your model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c1224",
   "metadata": {},
   "source": [
    "To compute the mean embedding for each review, and multiply it by the square root of the number of words in that review, we will need a little function. For each sentence, this function needs to compute $M \\times \\sqrt{N}$, where $M$ is the mean of all the word embeddings in the sentence (excluding padding tokens), and $N$  is the number of words in the sentence (also excluding padding tokens). We can rewrite $M$ as $\\frac{S}{N}$, where $S$ is the sum of all word embeddings (it does not matter whether or not we include the padding tokens in this sum, since their representation is a zero vector). So the function must return $M \\times \\sqrt{N} = \\frac{S}{\\sqrt{N}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c971b4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.535534 , 4.9497476, 2.1213205],\n",
       "       [6.       , 0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_mean_embedding(inputs):\n",
    "    not_pad = tf.math.count_nonzero(inputs, axis=-1)\n",
    "    n_words = tf.math.count_nonzero(not_pad, axis=-1, keepdims=True)    \n",
    "    sqrt_n_words = tf.math.sqrt(tf.cast(n_words, tf.float32))\n",
    "    return tf.reduce_sum(inputs, axis=1) / sqrt_n_words\n",
    "\n",
    "another_example = tf.constant([[[1., 2., 3.], [4., 5., 0.], [0., 0., 0.]],\n",
    "                               [[6., 0., 0.], [0., 0., 0.], [0., 0., 0.]]])\n",
    "compute_mean_embedding(another_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfebbf9f",
   "metadata": {},
   "source": [
    "Perfect. Now we're ready to train our final model. It's the same as before, except we replaced the `BagOfWords` layer with an `Embedding` layer followed by a Lambda layer that calls the compute_mean_embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "43707511",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 20\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    text_vectorization,\n",
    "    keras.layers.Embedding(input_dim=n_tokens,\n",
    "                           output_dim=embedding_size,\n",
    "                           mask_zero=True), # <pad> tokens => zero vectors\n",
    "    keras.layers.Lambda(compute_mean_embedding),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a90d0b",
   "metadata": {},
   "source": [
    "**f. Train the model and see what accuracy you get. Try to optimize your pipelines to make training as fast as possible.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3fc642b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.5547 - accuracy: 0.7092 - val_loss: 0.5092 - val_accuracy: 0.7391\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4941 - accuracy: 0.7558 - val_loss: 0.5062 - val_accuracy: 0.7409\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4818 - accuracy: 0.7605 - val_loss: 0.5009 - val_accuracy: 0.7431\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4736 - accuracy: 0.7651 - val_loss: 0.5056 - val_accuracy: 0.7429\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.4654 - accuracy: 0.7679 - val_loss: 0.5061 - val_accuracy: 0.7441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f114b4889d0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b55a14",
   "metadata": {},
   "source": [
    "The model is not better using embeddings (but we will do better in Chapter 16). The pipeline looks fast enough (we optimized it earlier)."
   ]
  }
 ],
 "metadata": {
  "author": "mes",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
