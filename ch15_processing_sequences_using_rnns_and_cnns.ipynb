{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "509b6dac",
   "metadata": {},
   "source": [
    "# Chapter 15 - Processing Sequences Using RNNs and CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b51ba",
   "metadata": {},
   "source": [
    "In this chapter we will first look at the fundamental concepts underlying Recurrent Neural Networks (RNNs)\n",
    "and how to train them using backpropagation through time, then we will use\n",
    "them to forecast a time series. After that we’ll explore the two main difficulties\n",
    "that RNNs face:\n",
    "\n",
    "- Unstable gradients (discussed in Chapter 11), which can be alleviated\n",
    "using various techniques, including recurrent dropout and recurrent\n",
    "layer normalization\n",
    "\n",
    "- A (very) limited short-term memory, which can be extended using\n",
    "LSTM and GRU cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c33801",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Recurrent Neurons and Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3010087",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The simplest possible RNN is composed of one neuron receiving inputs, producing and output, and sending theat output back to itself. Each recurrent neuron has two sets of weights: one for the inputs $\\pmb{x}_{t}$ and the other for the outputs of the previous time step, $\\pmb{y}_{t-1}$. We can extend this architecture to a layer of Recurrent Neurons, and replace weight vectors for weight matrices $\\pmb{W}_x$ for the input weights, and $\\pmb{W}_y$, plus a bias term $\\pmb{b}$:\n",
    "\n",
    "![rnn_layers](./images/ch15_rnn_layer.png)\n",
    "\n",
    "The output produce by a layer at time $t$ is given by the equation:\n",
    "\n",
    "$$\n",
    "\\pmb{y}(t) = \\phi(\\pmb{W}_x^T\\pmb{x}_{(t)} + \\pmb{W}_y^T\\pmb{y}_{(t-1)} + \\pmb{b})\n",
    "$$\n",
    "\n",
    "Just as with feedforward neural networks, we can compute a recurrent layer’s\n",
    "output in one shot for a whole mini-batch by placing all the inputs at time step $t$\n",
    "in an input matrix $\\pmb{X}_t$:\n",
    "\n",
    "$$\n",
    "\\pmb{Y}(t) = \\phi(\\pmb{X}_{(t)}\\pmb{W}_x + \\pmb{Y}_{(t-1)}\\pmb{W}_y + \\pmb{b})\n",
    "= \\phi([\\pmb{X}_{(t)} + \\pmb{Y}_{(t-1)}]\\pmb{W} + \\pmb{b})\n",
    "$$\n",
    "\n",
    "with $\\pmb{W} = \\begin{bmatrix} \\pmb{W}_x \\\\ \\pmb{W}_y \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97851e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Memory Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17366305",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since the output of a recurrent neuron at time step t is a function of all the inputs\n",
    "from previous time steps, you could say it has a form of memory. A part of a\n",
    "neural network that preserves some state across time steps is called a memory\n",
    "cell (or simply a cell). A single recurrent neuron, or a layer of recurrent neurons,\n",
    "is a very basic cell, capable of learning only short patterns (typically about 10\n",
    "steps long, but this varies depending on the task)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1948a1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Input and Output Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad6609",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![input_output](./images/ch15_input_output_seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65564ec1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Applications:\n",
    "\n",
    "- seq-to-seq: Predicting stock prices\n",
    "- seq-to-vector: Text sentiment analysis\n",
    "- vector-to-seq: Image caption\n",
    "- Encoder-Decoder: Translating sentence from one language to another"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72551ef6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa41bd6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To train an RNN, the trick is to unroll it through time (like we just did) and then\n",
    "simply use regular backpropagation (see Figure 15-5). This strategy is called\n",
    "*backpropagation through time* (BPTT).\n",
    "\n",
    "![bptt](./images/ch15_bptt.png)\n",
    "\n",
    "Depending on the task, the cost function $C$ may use all outputs, or just a subset of them. In the example above, it uses the last three outputs, but if the task was a sequence-to-vector, it would only use the last one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c9e8d",
   "metadata": {},
   "source": [
    "## Forecasting a Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed05b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:00:35.849948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-14 15:00:35.849973: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd80560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 20))  # wave 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d5dc9",
   "metadata": {},
   "source": [
    "This function creates as many time series as requested (via the `batch_size`\n",
    "argument), each of length `n_steps`, and there is just one value per time step in\n",
    "each series (i.e., all series are univariate). The function returns a NumPy array of\n",
    "shape `[batch size, time steps, 1]`, where each series is the sum of two sine waves\n",
    "of fixed amplitudes but random frequencies and phases, plus a bit of noise.\n",
    "\n",
    "Now, let's create a training set, a validation set, and a test set using this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad605b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89a6d2",
   "metadata": {},
   "source": [
    "`X_train` contains 7000 time series (i.e., its shape is [7000, 50, 1]), while `X_valid` contains 2000 and `X_test` contains 1000. Since we want to forecast a single value for each series, the targets are column vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcf503",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Baseline Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a021ea",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is important to define the metrics to evaluate our models. The simplest approach is to predict the last value in each series. this is called *naive forecasting*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "940a0cc5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040211584"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f0c01",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another simple approach is to use a fully connected network. Since it expects a flat list of features for each input, we need to add a `Flatten` layer. Let's implement a simple linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84141509",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 0s 560us/step - loss: 0.0953\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 543us/step - loss: 0.0172\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 559us/step - loss: 0.0096\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 540us/step - loss: 0.0071\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 540us/step - loss: 0.0055\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 558us/step - loss: 0.0046\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 541us/step - loss: 0.0040\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 548us/step - loss: 0.0037\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 553us/step - loss: 0.0036\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 553us/step - loss: 0.0035\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 537us/step - loss: 0.0034\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 546us/step - loss: 0.0033\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 554us/step - loss: 0.0033\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 551us/step - loss: 0.0032\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 580us/step - loss: 0.0031\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 561us/step - loss: 0.0031\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 570us/step - loss: 0.0030\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 628us/step - loss: 0.0029\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 578us/step - loss: 0.0029\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 538us/step - loss: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9940309400>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3dedf50",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 524us/step - loss: 0.0030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002967239124700427"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a072fcf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using this approach, we got a MSE of 0.00297 on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e14de9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Implementing a Simple RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc538c90",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, let's use the simplest RNN we can build to perform this task. It just contains a single layer, with a single neuron. We do not need to specify the length of the input sequences (unlike in the previous model) since a rnn can process any number of time steps (this is why we set the first input dimension to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13a88c23",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1388\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1387\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1384\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1385\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1388\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1381\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1384\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1386\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1382\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1389\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1384\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1384\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1384\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1381\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1383\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1388\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1386\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1385\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1386\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9940217430>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1b25e79",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1439523547887802"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c135f03",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we can see, the performance of this RNN was worse than the Neural Network (linear model). It looks like our RNN is too simple to get good performance. Next, let's try a deep RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66ac3f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By default, recurrent layers in Keras only return the final output. To make them return one output per time step, you must set `return_sequences=True`|, as we will see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8cf70b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Deep RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48040272",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is quite common to stack multiple layers of cells, like in the figure 15-7. This gives you a deep RNN.\n",
    "\n",
    "![deep_rnn](./images/ch15_deep_rnn.png)\n",
    "\n",
    "Implementing a deep RNN with `tf.keras` is quite simple: just stack recurrent\n",
    "layers. In this example, we use three `SimpleRNN` layers (but we could add any\n",
    "other type of recurrent layer, such as an `LSTM` layer or a `GRU` layer, which we will\n",
    "discuss shortly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2836aee2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 4s 14ms/step - loss: 0.0358\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0062\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0046\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0037\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0034\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0032\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0030\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0029\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0027\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0027\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0027\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0027\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0028\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0025\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0027\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0026\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0025\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0024\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0024\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99402f19d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee42b26d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0027131850365549326"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41f9dd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And bang! we beat the linear model with 0.00271 MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a46b2f1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that the last layer is not ideal: it must have a single unit because we want to\n",
    "forecast a univariate time series, and this means we must have a single output\n",
    "value per time step. \n",
    "\n",
    "However, having a single unit means that the hidden state is\n",
    "just a single number. That’s really not much, and it’s probably not that useful;\n",
    "presumably, the RNN will mostly use the hidden states of the other recurrent\n",
    "layers to carry over all the information it needs from time step to time step, and\n",
    "it will not use the final layer’s hidden state very much. \n",
    "\n",
    "Moreover, since a `SimpleRNN` layer uses the `tanh` activation function by default, the predicted\n",
    "values must lie within the range –1 to 1. But what if you want to use another\n",
    "activation function? For both these reasons, it might be preferable to replace the\n",
    "output layer with a `Dense` layer: it would run slightly faster, the accuracy would\n",
    "be roughly the same, and it would allow us to choose any output activation\n",
    "function we want. If you make this change, also make sure to remove\n",
    "`return_sequences=True` from the second (now last) recurrent layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1f102d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 3s 10ms/step - loss: 0.0142\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0033\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0029\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0027\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0025\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0025\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0024\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0024\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0023\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0023\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0022\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0022\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0023\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0023\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0022\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0022\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0022\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0022\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0023\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9939fa2a90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4ab5f0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002368667395785451"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc384a1a",
   "metadata": {},
   "source": [
    "### Forecasting Several Time Steps Ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152abfb",
   "metadata": {},
   "source": [
    "So far, we've dedicated our studies in predicting the next value of the series. But what if we want to predict the next 10 values of the series? There are two possible approaches for this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4f458",
   "metadata": {},
   "source": [
    "1. The first option is to use the model we already trained, make it predict the next value, then add that value to the inputs (acting as if this predicted value had actually occured), and use the model again to predict the following value, and so on, as in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf1f0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new \n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    \n",
    "Y_pred = X[:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7681fce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031221583"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(keras.metrics.mean_squared_error(Y_pred, Y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41bd1e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.34370846],\n",
       "        [ 0.21279262],\n",
       "        [-0.02680342],\n",
       "        [-0.15851194],\n",
       "        [-0.31637913],\n",
       "        [-0.38260907],\n",
       "        [-0.3879037 ],\n",
       "        [-0.34886643],\n",
       "        [-0.24574944],\n",
       "        [-0.16358002]]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360bc946",
   "metadata": {},
   "source": [
    "2. The second option is to train an RNN to predict all 10 next values at once. We can still use a sequence-to-vector model, but it will output 10 values instead of 1. However, we first need to change the targets to be vectors containing the next 10 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b32937be",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b3282",
   "metadata": {},
   "source": [
    "Now we just need the output layer to have 10 units instead of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f0f0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 3s 11ms/step - loss: 0.0515\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0171\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0122\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0102\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0094\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0090\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0084\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0079\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0078\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0076\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0074\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0074\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0070\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0072\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0070\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0070\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0069\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0069\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0068\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9939a8c460>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91289a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006903470028191805"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be4606a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85e70302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22924933"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(keras.metrics.mean_squared_error(Y_pred, Y_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea1ece5",
   "metadata": {},
   "source": [
    "In this particular case, the first approach was much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d18d7274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42717203,  0.16126128, -0.08839938, -0.36850065, -0.5211376 ,\n",
       "        -0.56968665, -0.5459968 , -0.42273957, -0.2622762 , -0.10547987]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64d65f",
   "metadata": {},
   "source": [
    "We can still improve on this solution: indeed, instead of training the model to forecast the next 10 values only at the very last time step, we can train it to forecast the next 10 values at each and every time\n",
    "step. In other words, we can turn this sequence-to-vector RNN into a sequenceto-sequence RNN. The advantage of this technique is that the loss will contain a term for the output of the RNN at each and every time step, not just the output at the last time step. This means there will be many more error gradients flowing through the model, and they won’t have to flow only through time; they will also flow from the output of each time step. This will both stabilize and speed up training.\n",
    "\n",
    "To be clear, at time step 0 the model will output a vector containing the forecasts\n",
    "for time steps 1 to 10, then at time step 1 the model will forecast time steps 2 to\n",
    "11, and so on. So each target must be a sequence of the same length as the input\n",
    "sequence, containing a 10-dimensional vector at each step. Let’s prepare these\n",
    "target sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "125433cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.empty((10000, n_steps, 10)) # each target is a sequence of 10D vectors\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:, :, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]\n",
    "Y_train = Y[:7000]\n",
    "Y_valid = Y[7000:9000]\n",
    "Y_test = Y[9000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3dfef5",
   "metadata": {},
   "source": [
    "To turn the model into a sequence-to-sequence model, we must set\n",
    "`return_sequences=True` in all recurrent layers (even the last one), and we must\n",
    "apply the output Dense layer at every time step. Keras offers a\n",
    "TimeDistributed layer for this very purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b19d9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ac2ed",
   "metadata": {},
   "source": [
    "All outputs are needed during training, but only the output at the last time step is\n",
    "useful for predictions and for evaluation. So although we will rely on the MSE\n",
    "over all the outputs for training, we will use a custom metric for evaluation, to\n",
    "only compute the MSE over the output at the last time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "903b7fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 3s 11ms/step - loss: 0.0238 - last_time_step_mse: 0.0157\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0208 - last_time_step_mse: 0.0130\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0198 - last_time_step_mse: 0.0121\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0189 - last_time_step_mse: 0.0112\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0182 - last_time_step_mse: 0.0105\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0175 - last_time_step_mse: 0.0100\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0167 - last_time_step_mse: 0.0092\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0163 - last_time_step_mse: 0.0089\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0161 - last_time_step_mse: 0.0088\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0158 - last_time_step_mse: 0.0085\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0156 - last_time_step_mse: 0.0083\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0154 - last_time_step_mse: 0.0083\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0152 - last_time_step_mse: 0.0082\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0150 - last_time_step_mse: 0.0080\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0149 - last_time_step_mse: 0.0079\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0148 - last_time_step_mse: 0.0080\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0145 - last_time_step_mse: 0.0078\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0144 - last_time_step_mse: 0.0078\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0142 - last_time_step_mse: 0.0077\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0142 - last_time_step_mse: 0.0077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9939270940>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "770ada14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0146 - last_time_step_mse: 0.0080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01456688903272152, 0.00796412955969572]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97478b",
   "metadata": {},
   "source": [
    "In this example, we didn't get any improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d0bc1",
   "metadata": {},
   "source": [
    "## Handling Long Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2875f5d",
   "metadata": {},
   "source": [
    "To train an RNN on long sequences, we must run it over many time steps,\n",
    "making the unrolled RNN a very deep network. Just like any deep neural\n",
    "network it may suffer from the **unstable gradients problem**, discussed in Chapter\n",
    "11: it may take forever to train, or training may be unstable. Moreover, when an\n",
    "RNN processes a long sequence, it will gradually **forget the first inputs in the\n",
    "sequence**. Let’s look at both these problems, starting with the unstable gradients\n",
    "problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ceb074",
   "metadata": {},
   "source": [
    "### Fighting the Unstable Gradients Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb1d19",
   "metadata": {},
   "source": [
    "Many of the tricks we learned in the context of deep nets to alleviate the unstable gradients problem can also be used of RNNs: good parameter initialization, faster optimizers, dropout and so on. However, Non-saturating activation functions (ReLU) may not help here. The accumulation of gradients at every step makes the gradients explode. That's why the default activation function is the hyperbolic tangent, which saturates and limit the gradients. \n",
    "\n",
    "Moreover, Batch Normalization cannot be used as efficiently with RNNs. It was found that BN was slightly beneficial only when it was applied to the **inputs**, **not to the hidden states**. In other words, it was slightly better than nothing when applied between recurrent layers (i.e., vertically in Figure 15-7), but not within recurrent layers (i.e., horizontally). In Keras this can be done simply by adding a BatchNormalization layer before each recurrent layer, but don’t expect too much from it.\n",
    "\n",
    "Another form of normalization often workss better with RNNs: *Layer Normalization*. In an RNN, it is typically used right after the linear combination of the inputs and the hidden states.\n",
    "\n",
    "Let’s use `tf.keras` to implement Layer Normalization within a simple memory cell. For this, we need to define a custom memory cell. It is just like a regular layer, except its `call()` method takes two arguments: the inputs at the current time step and the hidden states from the previous time step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e9c11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSimpleRNNCell(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.outputs_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units, activation=None)\n",
    "        self.layer_norm = keras.layers.LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    \n",
    "    \n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]\n",
    "    \n",
    "# It would have been simpler to inherit from SimpleRNNCell instead so that we wouldn’t have to\n",
    "# create an internal SimpleRNNCell or handle the state_size and output_size attributes, but the\n",
    "# goal here was to show how to create a custom cell from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a83e1",
   "metadata": {},
   "source": [
    "The `call()` method starts by applying the simple RNN cell, which\n",
    "computes a linear combination of the current inputs and the previous hidden\n",
    "states, and it returns the result twice (indeed, in a SimpleRNNCell, the outputs\n",
    "are just equal to the hidden states: in other words, `new_states[0]` is equal to\n",
    "outputs, so we can safely ignore new_states in the rest of the `call()` method).\n",
    "Next, the `call()` method applies Layer Normalization, followed by the\n",
    "activation function. Finally, it returns the outputs twice (once as the outputs, and\n",
    "once as the new hidden states). To use this custom cell, all we need to do is\n",
    "create a `keras.layers.RNN` layer, passing it a cell instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "62b76923",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
    "                     input_shape=[None, 1]),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "531e4412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 6s 21ms/step - loss: 0.1160 - last_time_step_mse: 0.0959\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0411 - last_time_step_mse: 0.0290\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0341 - last_time_step_mse: 0.0234\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0297 - last_time_step_mse: 0.0203\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0259 - last_time_step_mse: 0.0174\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0228 - last_time_step_mse: 0.0149\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0206 - last_time_step_mse: 0.0130\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0195 - last_time_step_mse: 0.0121\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0186 - last_time_step_mse: 0.0114\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0181 - last_time_step_mse: 0.0110\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0175 - last_time_step_mse: 0.0106\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0171 - last_time_step_mse: 0.0104\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0169 - last_time_step_mse: 0.0102\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0165 - last_time_step_mse: 0.0100\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0162 - last_time_step_mse: 0.0099\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0159 - last_time_step_mse: 0.0097\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0156 - last_time_step_mse: 0.0095\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0153 - last_time_step_mse: 0.0093\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0151 - last_time_step_mse: 0.0093\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0148 - last_time_step_mse: 0.0090\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3af874f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 6ms/step - loss: 0.0149 - last_time_step_mse: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.014905747026205063, 0.009058771654963493]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e1ccf",
   "metadata": {},
   "source": [
    "### Tackling the Short-Term Memory Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501513d",
   "metadata": {},
   "source": [
    "Various types of cells with long-term memory have been introduced to mitigate the short-term memory problem. They have proven so successful that the basic cells we've been using until now are not used much anymore. Let’s first look at the most popular of these long-term memory cells: the LSTM cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a4e22b",
   "metadata": {},
   "source": [
    "#### LSTM cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677998f",
   "metadata": {},
   "source": [
    "The Long Short-Term Memory (LSTM) cell was proposed in 1997. If you consider the LSTM cell as a black box, it can be used very much like a basic cell, except it will perform much better; training will converge faster, and it will detect long-term dependencies in the data. In Keras, you can simply use the LSTM layer instead of the SimpleRNN layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "91e8ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 7s 20ms/step - loss: 0.0627 - last_time_step_mse: 0.0518\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0283 - last_time_step_mse: 0.0162\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0215 - last_time_step_mse: 0.0103\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 4s 19ms/step - loss: 0.0193 - last_time_step_mse: 0.0094\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0182 - last_time_step_mse: 0.0091\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0174 - last_time_step_mse: 0.0089\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0167 - last_time_step_mse: 0.0085\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0159 - last_time_step_mse: 0.0080\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0153 - last_time_step_mse: 0.0075\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0148 - last_time_step_mse: 0.0072\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0144 - last_time_step_mse: 0.0069\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0140 - last_time_step_mse: 0.0067\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0138 - last_time_step_mse: 0.0066\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0136 - last_time_step_mse: 0.0066\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0133 - last_time_step_mse: 0.0064\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0132 - last_time_step_mse: 0.0063\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0130 - last_time_step_mse: 0.0063\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0128 - last_time_step_mse: 0.0062\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0127 - last_time_step_mse: 0.0062\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0126 - last_time_step_mse: 0.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98fb981f40>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b319cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 5ms/step - loss: 0.0129 - last_time_step_mse: 0.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.012923017144203186, 0.006200644187629223]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514cc8d",
   "metadata": {},
   "source": [
    "This is the best result we've obtained so far. So how does an LSTM cell work? Its architecture is shown in Figure 15-9.\n",
    "\n",
    "![lstm_architecture](./images/ch15_lstm_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc754446",
   "metadata": {},
   "source": [
    "If you don’t look at what’s inside the box, the LSTM cell looks exactly like a\n",
    "regular cell, except that its state is split into two vectors: $\\pmb{h}_{(t)}$ and $\\pmb{c}_{(t)}$ (\"c\" stands\n",
    "for \"cell\"). You can think of $\\pmb{h}_{(t)}$ as the **short-term state** and $\\pmb{c}_{(t)}$ as the **long-term state**.\n",
    "\n",
    "The key idea is that the network can learn what to **store** in the long-term state, what to **throw away**, and what to **read** from it. These three operations are controlled by the three *gate controllers*: $\\pmb{f}_{(t)}$, $\\pmb{i}_{(t)}$, and $\\pmb{o}_{(t)}$.\n",
    "\n",
    "First, let's start with we already know. The gate $\\pmb{g}_{(t)}$ behaves exactly like the cells we've been dealing with so far. It has the usual role of analyzing the current input $\\pmb{x}_{(t)}$ and the previous (short-term) state $\\pmb{h}_{(t-1)}$. In a basic cell, there is nothing other than this layer, and its output goes straight to the output $\\pmb{y}_{(t)}$ and $\\pmb{h}_{(t)}$. \n",
    "\n",
    "The gate controllers are fully connected layers, responsible for filtering and selecting with informations will be passed through the network.\n",
    "\n",
    "- the forget gate ($\\pmb{f}_{(t)}$) controls which parts of the long-term state should be erased via and element-wise multiplication with the previous long-term memory state $\\pmb{c}_{(t-1)}$.\n",
    "\n",
    "- the input gate ($\\pmb{i}_{(t)}$) controls which parts of $\\pmb{g}_{(t)}$ should be added to the long-term state to yield the next long term state and also be passed through the $tanh$ activation.\n",
    "\n",
    "- the output gate ($\\pmb{o}_{(t)}$) control which parts of the long-term state should be read and output at this time step, both to $\\pmb{h}_{(t)}$ and $\\pmb{y}_{(t)}$.\n",
    "\n",
    "The following equations summarizes how to compute the cell's long-term state, its short-term state, and its output at each time step for a single instance.\n",
    "\n",
    "$$\n",
    "\\pmb{i}_{(t)} = \\sigma(\\pmb{W}_{xi}^T\\pmb{x}_{(t)} + \\pmb{W}_{hi}^T\\pmb{h}_{(t-1)} + \\pmb{b_i})\n",
    "\\\\\n",
    "\\pmb{f}_{(t)} = \\sigma(\\pmb{W}_{xf}^T\\pmb{x}_{(t)} + \\pmb{W}_{hf}^T\\pmb{h}_{(t-1)} + \\pmb{b_f})\n",
    "\\\\\n",
    "\\pmb{o}_{(t)} = \\sigma(\\pmb{W}_{xo}^T\\pmb{x}_{(t)} + \\pmb{W}_{ho}^T\\pmb{h}_{(t-1)} + \\pmb{b_o})\n",
    "\\\\\n",
    "\\pmb{g}_{(t)} = \\tanh(\\pmb{W}_{xg}^T\\pmb{x}_{(t)} + \\pmb{W}_{hg}^T\\pmb{h}_{(t-1)} + \\pmb{b_g})\n",
    "\\\\\n",
    "\\pmb{c}_{(t)} = \\pmb{f}_{(t)} \\otimes \\pmb{c}_{(t-1)} + \\pmb{i}_{(t)} \\otimes \\pmb{g}_{(t)}\n",
    "\\\\\n",
    "\\pmb{y}_{(t)} = \\pmb{h}_{(t)} = \\pmb{o}_{(t)} \\otimes \\tanh(\\pmb{c}_{(t)})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\pmb{W}_{xi}$, $\\pmb{W}_{xf}$, $\\pmb{W}_{xo}$, and $\\pmb{W}_{xg}$ are the weight matrices of each of the four layers for their connection to the input vector $\\pmb{x}_{(t)}$.\n",
    "- $\\pmb{W}_{hi}$, $\\pmb{W}_{hf}$, $\\pmb{W}_{ho}$, and $\\pmb{W}_{hg}$ are the weight matrices of each of the four layers for their connection to the previous short-term state $\\pmb{h}_{(t-1)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d94e48",
   "metadata": {},
   "source": [
    "#### Peephole connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd67775",
   "metadata": {},
   "source": [
    "There are many variants of the LSTM cell, one of them was proposed in 2000. This variant has extra connections called *peephole connections*: the previous long-term state $\\pmb{c}_{(t-1)}$ is added as an input to the controllers of the forget gate and the input gate, and the current long-term state $\\pmb{c}_{(t)}$ is added as input to the controller of the output gate. This often improves performance, but not always, and there is no clear pattern for which tasks are better off with or without them: you will have to try it on your task and see if it helps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ed5fb",
   "metadata": {},
   "source": [
    "#### GRU cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de6fad",
   "metadata": {},
   "source": [
    "The GRU cell is a simplified version of the LSTM cell, and it seems to perform just as well. These are the main simplifications:\n",
    "\n",
    "![gru_cells](./images/ch15_gru_cells.png)\n",
    "\n",
    "- Both state vectors (for short-term and long-term memory) are merged into a single vector $\\pmb{h}_{(t)}$.\n",
    "- A single gate controller $\\pmb{z}_{(t)}$ controls the forget gate and the input gate. If the gate controller outputs a 1, the forget gate is open (= 1) and the input gate is closed (1 – 1 = 0). If it outputs a 0, the opposite happens. In other words, whenever a memory must be stored, the location where it will be stored is erased first. This is actually a frequent variant to the LSTM cell in and of itself.\n",
    "- There is no output gate; the full state vector is output at every time step. However, there is a new gate controller $\\pmb{r}_{(t)}$ that controls which part of the previous state will be shown to the main layer ($\\pmb{g}_{(t)}$)\n",
    "\n",
    "The following equations summarizes how to compute the cell's state at each time for a single instance:\n",
    "\n",
    "$$\n",
    "\\pmb{z}_{(t)} = \\sigma(\\pmb{W}_{xz}^T\\pmb{x}_{(t)} + \\pmb{W}_{hz}^T\\pmb{h}_{(t-1)} + \\pmb{b_z})\n",
    "\\\\\n",
    "\\pmb{r}_{(t)} = \\sigma(\\pmb{W}_{xr}^T\\pmb{x}_{(t)} + \\pmb{W}_{hr}^T\\pmb{h}_{(t-1)} + \\pmb{b_r})\n",
    "\\\\\n",
    "\\pmb{g}_{(t)} = \\tanh(\\pmb{W}_{xg}^T\\pmb{x}_{(t)} + \\pmb{W}_{hg}^T(\\pmb{r}_{(t)} \\otimes \\pmb{h}_{(t-1)}) + \\pmb{b_g})\n",
    "\\\\\n",
    "\\pmb{z}_{(t)} = \\pmb{z}_{(t)} \\otimes \\pmb{h}_{(t-1)} + (1 - \\pmb{z}_{(t)}) \\otimes \\pmb{g}_{(t)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df26b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 7s 24ms/step - loss: 0.0604 - last_time_step_mse: 0.0550\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0258 - last_time_step_mse: 0.0198\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0216 - last_time_step_mse: 0.0151\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0190 - last_time_step_mse: 0.0126\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0176 - last_time_step_mse: 0.0112\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0167 - last_time_step_mse: 0.0106\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0160 - last_time_step_mse: 0.0101\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0154 - last_time_step_mse: 0.0096\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0150 - last_time_step_mse: 0.0092\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0145 - last_time_step_mse: 0.0087\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0141 - last_time_step_mse: 0.0082\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0138 - last_time_step_mse: 0.0078\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0136 - last_time_step_mse: 0.0076\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0134 - last_time_step_mse: 0.0074\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0133 - last_time_step_mse: 0.0073\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0131 - last_time_step_mse: 0.0072\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0130 - last_time_step_mse: 0.0070\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0128 - last_time_step_mse: 0.0070\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0127 - last_time_step_mse: 0.0069\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0126 - last_time_step_mse: 0.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99398472b0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b05d8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 5ms/step - loss: 0.0127 - last_time_step_mse: 0.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.012731347233057022, 0.006827231030911207]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40780197",
   "metadata": {},
   "source": [
    "The performance obtained using GRU in this case was a little worse than with LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb057a",
   "metadata": {},
   "source": [
    "LSTM and GRU cells are one of the main reasons behind the success of RNNs.\n",
    "Yet while they can tackle much longer sequences than simple RNNs, they still\n",
    "have a fairly limited short-term memory, and they have a hard time learning\n",
    "long-term patterns in sequences of 100 time steps or more, such as audio\n",
    "samples, long time series, or long sentences. One way to solve this is to shorten\n",
    "the input sequences, for example using 1D convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e4c66",
   "metadata": {},
   "source": [
    "#### Using 1D convolutional layers to process sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d59f0c",
   "metadata": {},
   "source": [
    "a 1D convolutional layer slides several kernels across a sequence, producing a 1D feature map per kernel. Each kernel will learn to detect a single very short sequential pattern (no longer than the kernel size). If you use 10 kernels, then the layer’s output will be composed of 10 1-dimensional sequences (all of the same length), or equivalently you can view this output as a single 10-dimensional sequence. This means that you can build a neural network composed of a mix of recurrent layers and 1D convolutional layers (or even 1D pooling layers). If you use a 1D convolutional layer with a stride of 1 and \"same\" padding, then the output sequence will have the same length as the input sequence. But if you use \"valid\" padding or a stride greater than 1, then the output sequence will be shorter than the input sequence, so make sure you adjust the targets accordingly. For example, the following model is the same as earlier, except it starts with a 1D convolutional layer that downsamples the input sequence by a factor of 2, using a stride of 2.\n",
    "\n",
    "Note that we must also crop off the first three time steps in the targets (since the kernel’s size is 4, the first output of the convolutional layer will be based on the input time steps 0 to 3), and downsample the targets by a factor of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b13c27de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 5s 13ms/step - loss: 0.0571 - last_time_step_mse: 0.0513\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0190 - last_time_step_mse: 0.0155\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0148 - last_time_step_mse: 0.0118\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0135 - last_time_step_mse: 0.0107\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0127 - last_time_step_mse: 0.0100\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0122 - last_time_step_mse: 0.0094\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0118 - last_time_step_mse: 0.0089\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0113 - last_time_step_mse: 0.0084\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0110 - last_time_step_mse: 0.0079\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0107 - last_time_step_mse: 0.0075\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0104 - last_time_step_mse: 0.0072\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0102 - last_time_step_mse: 0.0069\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0100 - last_time_step_mse: 0.0067\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0099 - last_time_step_mse: 0.0066\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0098 - last_time_step_mse: 0.0065\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0097 - last_time_step_mse: 0.0064\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0096 - last_time_step_mse: 0.0063\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0095 - last_time_step_mse: 0.0063\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 0.0095 - last_time_step_mse: 0.0063\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 14ms/step - loss: 0.0094 - last_time_step_mse: 0.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98fa6bf040>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\", \n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train[:, 3::2], epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4168551a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 3ms/step - loss: 0.0096 - last_time_step_mse: 0.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.009614660404622555, 0.006209068465977907]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid[:, 3::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b55628",
   "metadata": {},
   "source": [
    "Using this approach, we got a performance similar to the LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca752cb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb51c06",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1. Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN, and a vector-to-sequence RNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f219e5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sequence-to-sequence applications could be text translation or time-series forecasting. Sequence-to-vector could be a sentiment analysis task with text input data. Lastly, a vector-to-sequence application could be image captioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c7545",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**2. How many dimensions must the inputs of an RNN layer have? What\n",
    "does each dimension represent? What about its outputs?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d13c75",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An RNN layer must have three input dimensions *[batch_size, time_steps, dimensionality]*, even for 1-dimensional data, in which case the last coordinate would be 1. For example, if you want to process a batch containing 5 time series of 10 time steps each, with 2 values per time step (e.g., the temperature and the wind speed), the shape will be *[5, 10, 2]*.\n",
    "\n",
    "The output of an RNN varies according to the task, any task that is trying to predict a sequence, will have an output of *[batch_size, time_steps, dimensionality]*, and in case of a vector, it would have the dimension of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d6e241",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**3. If you want to build a deep sequence-to-sequence RNN, which RNN layers should have `return_sequences=True`? What about a sequence-to-vector RNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d83b4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All RNN inner layers must have `return_sequences=True`, in order to have sequences as outputs of the network in a sequence-to-sequence task. On the other hand, in sequence-to-vector approaches, the last RNN layer do not return a sequence, hence `return_sequences=False`. The task of defining the output dimensions is fit only for the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e50be8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**4. Suppose you have a daily univariate time series, and you want to forecast the next seven days. Which RNN architecture should you use?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c5cb4a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I would use a sequence-to-sequence RNN architecture. The input shape would be *[batch_size, time_steps, 1]* and the output *[batch_size, time_steps, 1]*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cc0d3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**5. What are the main difficulties when training RNNs? How can you handle them?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a4e93",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The two main problems that can arise when training RNNs are *unstable gradients* and *forgetting long sequences*.\n",
    "\n",
    "- *unstable gradients*: can be fought using regularization techniques, such as dropout, layer normalization, clipnorm or clip values (implemented in the optimizer) and saturating activation functions such as `tanh`.\n",
    "- *forgetting long sequences*: can be overcomed using LSTM/GRU cells, which are specialized for longer sequences. And if it is not enough, you can also deploy Convolutional layers to do the job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7e9253",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**6. Can you sketch the LSTM cell's architecture?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089ea513",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Yes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af46cff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**7. Why would you want to use 1D convolutional layers in an RNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ce604",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1D convolutional layers improve the capacity of the RNN to remember long term sequences. It act by reducing the time series, while learning to filter out \"uninportant\" parts of the series. This also reduces complexity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64d774",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**8. Which neural network architecture could you use to classify videos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f8f81",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To classify videos based on their visual content, one possible\n",
    "architecture could be to take (say) one frame per second, then run every\n",
    "frame through the same convolutional neural network (e.g., a pretrained\n",
    "Xception model, possibly frozen if your dataset is not large), feed the\n",
    "sequence of outputs from the CNN to a sequence-to-vector RNN, and\n",
    "finally run its output through a softmax layer, giving you all the class\n",
    "probabilities. For training you would use cross entropy as the cost\n",
    "function. If you wanted to use the audio for classification as well, you\n",
    "could use a stack of strided 1D convolutional layers to reduce the\n",
    "temporal resolution from thousands of audio frames per second to just\n",
    "one per second (to match the number of images per second), and\n",
    "concatenate the output sequence to the inputs of the sequence-to-vector\n",
    "RNN (along the last dimension)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
