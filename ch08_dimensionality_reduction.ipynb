{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8625c89",
   "metadata": {},
   "source": [
    "# Chapter 08 - Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47823a25",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## The curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f126d125",
   "metadata": {
    "hidden": true
   },
   "source": [
    "high-dimensional datasets are at risk of being very sparse: most training instances are likely to be far away\n",
    "from each other because they are trapped in a high-dimensional space. This also means that a new instance will likely be far away from any training instance, making predictions much less reliable than in lower dimensions, since they will be based on much larger extrapolations. In short, the more dimensions the training set has, the greater the risk of overfitting it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228eebe6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Main Approaches for dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a17456",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80278e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In most real-world problems, training instances are not spread out uniformly across all dimensions. Many features are almost constant, while others are highly correlated (as discussed earlier for MNIST). As a result, all training instances lie within (or close to) a much lower-dimensional subspace of the high-dimensional\n",
    "space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4fd2f7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Manifold learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e530776",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Put simply, a 2D manifold is a 2D shape that can be bent and twisted in a higher-dimensional space. More\n",
    "generally, a d-dimensional manifold is a part of an n-dimensional space (where d < n) that locally resembles a d-dimensional hyperplane. In the case of the Swiss roll, d = 2 and n = 3: it locally resembles a 2D plane, but it is rolled in the third dimension.\n",
    "\n",
    "Many dimensionality reduction algorithms work by modeling the manifold on which the training instances lie; this is called Manifold Learning. It relies on the manifold assumption, also called the manifold hypothesis, which holds that most real-world high-dimensional datasets lie close to a much lower-dimensional manifold. This assumption is very often empirically observed.\n",
    "\n",
    "The manifold assumption is often accompanied by another implicit assumption: that the task at hand (e.g., classification or regression) will be simpler if expressed in the lower-dimensional space of the manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5ae7c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PCA (Linear projections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404740d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Vanilla PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d8f62",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Principal Component Analysis (PCA) is by far the most popular dimensionality reduction algorithm. First it identifies the hyperplane that lies closest to the data, and then it projects the data onto it, just like in Figure 8-2 that lies below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ba491",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To criteria to choose the right hyperplane is to select the projected hyperplane that preserves the maximum variance, as it will most likely lose less information than the other projections. \n",
    "Another way to justify this choice is that it is the axis that minimizes the mean squared distance between the original dataset and its projection onto that axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb294d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "PCA identifies the axis that accounts for the largest amount of variance in the training set. Then, it draws another axis, each perpendicular to all others in order to count for the remaining dimensions. The i-th axis is called the i-th principal component.\n",
    "\n",
    "To find the principal components, PCA uses the SVD matrix factorization technique that decomposes a matrix in $U \\Sigma V^T$, where $V$ contains the unit vectors that define all principal components that we are looking for. Also, note that the data must be centered around 0 mean to perform PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2039b566",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "np.random.seed(4)\n",
    "m = 60\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "X = np.empty((m, 3))\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9fd73ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis=0)\n",
    "U, s, Vt = np.linalg.svd(X_centered)\n",
    "c1 = Vt.T[:, 0]\n",
    "c2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b7848e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76706ad1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X3D_inv = pca.inverse_transform(X2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80332598",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)\n",
    "        \n",
    "axes = [-1.8, 1.8, -1.3, 1.3, -1.0, 1.0]\n",
    "\n",
    "x1s = np.linspace(axes[0], axes[1], 10)\n",
    "x2s = np.linspace(axes[2], axes[3], 10)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "C = pca.components_\n",
    "R = C.T.dot(C)\n",
    "z = (R[0, 2] * x1 + R[1, 2] * x2) / (1 - R[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbd75564",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x273.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3.8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X3D_above = X[X[:, 2] > X3D_inv[:, 2]]\n",
    "X3D_below = X[X[:, 2] <= X3D_inv[:, 2]]\n",
    "\n",
    "ax.plot(X3D_below[:, 0], X3D_below[:, 1], X3D_below[:, 2], \"bo\", alpha=0.5)\n",
    "\n",
    "ax.plot_surface(x1, x2, z, alpha=0.2, color=\"k\")\n",
    "np.linalg.norm(C, axis=0)\n",
    "ax.add_artist(Arrow3D([0, C[0, 0]],[0, C[0, 1]],[0, C[0, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\"))\n",
    "ax.add_artist(Arrow3D([0, C[1, 0]],[0, C[1, 1]],[0, C[1, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\"))\n",
    "ax.plot([0], [0], [0], \"k.\")\n",
    "\n",
    "for i in range(m):\n",
    "    if X[i, 2] > X3D_inv[i, 2]:\n",
    "        ax.plot([X[i][0], X3D_inv[i][0]], [X[i][1], X3D_inv[i][1]], [X[i][2], X3D_inv[i][2]], \"k-\")\n",
    "    else:\n",
    "        ax.plot([X[i][0], X3D_inv[i][0]], [X[i][1], X3D_inv[i][1]], [X[i][2], X3D_inv[i][2]], \"k-\", color=\"#505050\")\n",
    "    \n",
    "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k+\")\n",
    "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k.\")\n",
    "ax.plot(X3D_above[:, 0], X3D_above[:, 1], X3D_above[:, 2], \"bo\")\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18, labelpad=10)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18, labelpad=10)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18, labelpad=10)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "# Note: If you are using Matplotlib 3.0.0, it has a bug and does not\n",
    "# display 3D graphs properly.\n",
    "# See https://github.com/matplotlib/matplotlib/issues/12239\n",
    "# You should upgrade to a later version. If you cannot, then you can\n",
    "# use the following workaround before displaying each 3D graph:\n",
    "# for spine in ax.spines.values():\n",
    "#     spine.set_visible(False)\n",
    "\n",
    "# save_fig(\"dataset_3d_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9738ea3f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Projecting down to d dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e3995b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To project the training set onto the hyperplane and obtain a reduced dataset $X_{d-proj}$\n",
    "of dimensionality d, compute the matrix multiplication of the training set\n",
    "matrix X by the matrix $W_d$, defined as the matrix containing the first d columns\n",
    "of V, as shown in Equation 8-2 below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e7d655",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$X_{d-proj} = X W_d$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ada0dc8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "W2 = Vt.T[:, :2]\n",
    "X2D = X_centered.dot(W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f3a35",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that this is the same as calling  \n",
    "\n",
    "```\n",
    "pca = PCA(n_components=2)\n",
    "X2D = pca.fit_transform(X)\n",
    "``` \n",
    "\n",
    "As we did before. That's because scikit-learn also used SVD decomposition to compute the PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469159b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Explained Variance Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994f7d9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another useful piece of information is the explained variance ratio of each principal component, available via the *explained_variance_ratio_* variable. The ratio indicates the proportion of the datasets variance that lies along each principal component. For example, lets look at the explained variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7429704",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explained_var = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "457cf79c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988804464429311"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(explained_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5e8e5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This indicates the reducing the dataset down to 2 dimensions kept 98.888% percent of information. Therefore, the third axis does not hold much variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a431076",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Choosing the right number of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c89a0f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are some ways to choose the right number of dimensions. We could set a threshold over the explained variance ratio vector, and only consider the number of dimensions equivalent to 95% percent of all variation in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af10f05c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pca = PCA()\n",
    "# pca.fit(X_train)\n",
    "# cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "# d = np.argmax(cumsum >= 0.95) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57469049",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Or we could simply pass a float to scikit-learn *PCA()*, and it will understand that we want to projecting down to the number of dimensions needed to achieve such explained variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "069e4005",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=0.95)\n",
    "# X_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66daa40d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Moreover, we also plot the number of dimensions vs the explained variance accumulated sum, and look for an elbow in the graph indicating that from that point, the explained variance remains approximately constant as the number of dimensions increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189ba8e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### PCA for compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebacbbd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is possible to use PCA for data compression. By doing so, we are capable to reduce the number of features in a dataset and consequently speed up training and save storage. On the other hand, we can apply PCA to compress a dataset and also decompress it. Of course, since the compression throws away some information about the data, the decompression won't give us exactly the original data. However, the results might still be pretty good.\n",
    "\n",
    "The following code compresses the MNIST dataset down to 154 dimensions, then uses the inverse_transform() method to decompress it back to 784 dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc7cee5b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pca = PCA(n_components = 154)\n",
    "# X_reduced = pca.fit_transform(X_train)\n",
    "# X_recovered = pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4425ac7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The equation of the inverse transformation is shown in Equation 8-3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf78e72",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$X_{recovered} = X_{d-proj}W_d^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea847142",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The mean squared distance between the original data and the reconstructed data (compressed and then decompressed) is called the reconstruction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165ca05",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Randomized PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd794b0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Scikit-learn let us choose which derivation from the PCA technique we want to choose provided at the argument *svd_solver*. Passing \"randomized\" as the argument, we allow the API to use an stochastic algorithm called Randomized PCA that quickly finds an approximation of the first d principal components. Its computational complexity is $O(m  d^2) + O(d^2)$, instead of $O(m  n^2) + O(n^2)$ for the full SVD approach, so\n",
    "it is dramatically faster than full SVD when d is much smaller than n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b4e9271",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# rnd_pca = PCA(n_components=154, svd_solver=\"randomized\")\n",
    "# X_reduced = rnd_pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1875de",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By default, svd_solver is actually set to \"auto\": Scikit-Learn automatically uses the randomized PCA algorithm if m or n is greater than 500 and d is less than 80% of m or n, or else it uses the full SVD approach. If you want to force Scikit-Learn to use full SVD, you can set the svd_solver hyperparameter to \"full\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ec742",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Incremental PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743cc2f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One huge disadvantage of PCA is that we need to feed the whole data to the PCA function. Fortunately, *Incremental PCA (IPCA)* algorithms have been developed. They allow us to feed part of the data into the PCA algorithm such that we can use it iteratively to train PCA on the fly:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740cc918",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following code splits the MNIST dataset into 100 mini-batches (using NumPys array_split() function) and feeds them to Scikit-Learns *IncrementalPCA* class to reduce the dimensionality of the MNIST dataset down to 154 dimensions (just like before). Note that you must call the *partial_fit()* method with each mini-batch, rather than the *fit()* method with the whole training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c4e5a60",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "# n_batches = 100\n",
    "# inc_pca = IncrementalPCA(n_components=154)\n",
    "\n",
    "# for X_batch in np.array_split(X_train, n_batches):\n",
    "#   inc_pca.partial_fit(X_batch)\n",
    "#   X_reduced = inc_pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee680aa",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Kernel PCA (Nonlinear projections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff491c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In Chapter 5 we discussed the kernel trick, a mathematical technique that implicitly maps instances into a very high-dimensional space (called the feature space), enabling nonlinear classification and regression with Support Vector Machines. Recall that a linear decision boundary in the high-dimensional feature space corresponds to a complex nonlinear decision boundary in the original space.\n",
    "\n",
    "It turns out that the same trick can be applied to PCA, making it possible to perform complex nonlinear projections for dimensionality reduction. This is called Kernel PCA (kPCA). It is often good at preserving clusters of instances after projection, or sometimes even unrolling datasets that lie close to a twisted\n",
    "manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b91b6e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The idea here is quite the same, this technique is call *Kernel PCA (kPCA)*, and we can use Scikit-Learn's *KernelPCA* class to perform kPCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcbdf03f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)\n",
    "# X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d104790f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is often good at preserving clusters of instances after projection, or sometimes even unrolling datasets that lie close to a twisted manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d78b7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Selecting a Kernel and Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98517678",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Selecting a kernel and the best parameters is no trivial task. However, keep in mind that often, dimensionality reduction is just a preparation step to another task (classification, regression). In such cases, we can play with the parameters by doing a Grid Search CV over the parameters of kPCA in order to maximize a chosen metrics, such as accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f46a1e0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KernelPCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-51dad3b1aaea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m clf = Pipeline([\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0;34m\"kpca\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKernelPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0;34m\"log_reg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KernelPCA' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "  (\"kpca\", KernelPCA(n_components=2)),\n",
    "  (\"log_reg\", LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid = [{\n",
    "  \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
    "  \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3868942",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best kernel and hyperparameters are then available through the *best_params_* variable: `grid_search.best_params_`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85e877",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another Another approach, this time entirely unsupervised, is to select the kernel and\n",
    "hyperparameters that yield the lowest reconstruction error. Since we are talking about kPCA, the reconstruction is not as easy as for the linear PCA (standard PCA), beyond the dimensionality reduction, we also have a feature map step because of the kernel transformation.\n",
    "\n",
    "Notice that if we could invert the linear PCA step for a given instance in the reduced space, the reconstructed point would lie in feature space, not in the original space. Since the feature space is infinite-dimensional, we cannot compute the reconstructed point, and therefore we cannot compute the true reconstruction error. Fortunately, it is possible to find a point in the original space that would map close to the reconstructed point. This point is called the reconstruction pre-image. Once you have this pre-image, you can measure its squared distance to the original instance. You can then select the kernel and hyperparameters that minimize this reconstruction pre-image error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa3a0b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You may be wondering how to perform this reconstruction. One solution is to train a supervised regression model, with the projected instances as the training set and the original instances as the targets. Scikit-Learn will do this automatically if you set *fit_inverse_transform=True*, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31aaa2a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433, fit_inverse_transform=True)\n",
    "\n",
    "X_reduced = rbf_pca.fit_transform(X)\n",
    "X_preimage = rbf_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b6f0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(X, X_preimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2562a4c7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you can use grid search with cross-validation to find the kernel and hyperparameters that minimize this error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d118cb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d58e31",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Until this point, we have only learned about dimensionality reduction techniques based on projection. Locally Linear Embedding is a powerful nonlinear dimensionality reduction technique. It is a Manifold Learning technique that does not rely on projections, like the previous algorithms do. In a nutshell, LLE works by first measuring how each training instance linearly relates to its closest neighbors (c.n.), and then looking for a low-dimensional representation of the training set where these local relationships are best preserved (more details\n",
    "shortly). This approach makes it particularly good at unrolling twisted manifolds, especially when there is not too much noise.\n",
    "\n",
    "Heres how LLE works: for each training instance $x^{(i)}$, the algorithm identifies its k closest neighbors (in the preceding code k = 10), then tries to reconstruct $x^{(i)}$ as a linear function of these neighbors. More specifically, it finds the weights $w_{i, j}$ s.t. the squared distance between $x^{(i)}$ and $\\sum_{j=1}^m w_{i, j}x^{(j)}$ is as small as possible, assuming $w_{i, j} = 0$ if $x^{(j)}$ is not one of the k closest neighbors of $x^{(i)}$.\n",
    "\n",
    "$$\n",
    "\\hat{W} = argmin_W \\sum_{i=1}^m (x^{(i)} - \\sum_{j=1}^m w_{i,j}x^{(j)})^2\n",
    "$$\n",
    "\n",
    "\n",
    "After this step, the weight matrix $\\hat{W}$ (containing the weights $\\hat{w}_{i,j}$) encodes the\n",
    "local linear relationships between the training instances. The second step is to map the training instances into a d-dimensional space (where d < n) while preserving these local relationships as much as possible. If $z^{(i)}$ is the image of $x^{(i)}$ in this d-dimensional space, then we want the squared distance between $z^{(i)}$ and $\\sum_{j=1}^m \\hat{w}_{i, j}z^{(j)}$ to be as small as possible. This idea leads to the unconstrained\n",
    "optimization problem described in Equation 8-5. It looks very similar to the first step, but instead of keeping the instances fixed and finding the optimal weights, we are doing the reverse: keeping the weights fixed and finding the optimal position of the instances images in the low-dimensional space.\n",
    "\n",
    "$$\n",
    "\\hat{Z} = argmin_Z \\sum_{i=1}^m (z^{(i)} - \\sum_{j=1}^m \\hat{w}_{i,j}z^{(j)})^2\n",
    "$$\n",
    "\n",
    "Scikit-Learns LLE implementation has the following computational complexity:\n",
    "$O(m log(m)n log(k))$ for finding the k nearest neighbors, $O(mnk^2)$ for optimizing\n",
    "the weights, and $O(dm^2)$ for constructing the low-dimensional representations.\n",
    "Unfortunately, the $m^2$ in the last term makes this algorithm scale poorly to very\n",
    "large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f62167",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "# lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10)\n",
    "# X_reduced = lle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2dfe1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Other dimensionality reduction techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2862da",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae691a98",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As its name suggests, projects the data to a lower-dimensional space using a random linear projection. This may sound crazy, but it turns out that such a random projection is actually very likely to preserve distances well, as was demonstrated mathematically by William B. Johnson and Joram Lindenstrauss in a famous lemma. The quality of the dimensionality reduction depends on the number of instances and the target dimensionality, but surprisingly not on the initial dimensionality. Check out the documentation for the *sklearn.random_projection* package for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aeca27",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Multidimensional Scaling (MDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fbd60",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Reduces dimensionality while trying to preserve the distances between the instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e62d40",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Isomap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bdf04",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creates a graph by connecting each instance to its nearest neighbors, then reduces dimensionality while trying to preserve the geodesic distances between the instances.\n",
    "\n",
    "The geodesic distance between two nodes in a graph is the number of nodes on the shortest path between these nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01643370",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### t-Distributed Stochastic Neighbor Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6f5df5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Reduces dimensionality while trying to keep similar instances close and dissimilar instances apart. It is mostly used for visualization, in particular to visualize clusters of instances in high-dimensional space (e.g., to visualize the MNIST images in 2D)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03854d16",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a6b45",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Is a classification algorithm, but during training it learns the most discriminative axes between the classes, and these axes can then be used to define a hyperplane onto which to project the data. The benefit of this approach is that the projection will keep classes as far apart as possible, so LDA is a good technique to reduce dimensionality before running another classification algorithm such as an SVM classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
